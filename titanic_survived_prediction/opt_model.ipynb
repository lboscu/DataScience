{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_data = './all/'\n",
    "df_train = pd.read_csv(path_data + 'train.csv')\n",
    "df_test = pd.read_csv(path_data + 'test.csv')\n",
    "df_data = pd.concat([df_train, df_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Embarked'].fillna(df_data['Embarked'].mode()[0], inplace=True)\n",
    "df_data['Fare'].fillna(df_data['Fare'].median(), inplace=True)\n",
    "df_data['Cabin'] = df_data['Cabin'].apply(lambda x:x[0] if x is not np.nan else 'X')\n",
    "cabin_counts = df_data['Cabin'].value_counts()\n",
    "df_data['Cabin'] = df_data['Cabin'].apply((lambda x:'X' if cabin_counts[x] < 10 else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否有着家人一起\n",
    "df_data['FamilySize'] = df_data['SibSp'] + df_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\program files\\python3.6.4\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#是否独自一人\n",
    "df_data['IsAlone'] = 1\n",
    "df_data['IsAlone'].loc[df_data['FamilySize'] > 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#称谓表示身份的不同\n",
    "df_data['Title'] = df_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "title_counts = df_data['Title'].value_counts()\n",
    "df_data['Title'] = list(map(lambda x:'Rare' if title_counts[x] < 10 else x, df_data['Title'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有着相同姓氏的人，可能是一个家庭\n",
    "df_data['Family_Name'] = df_data['Name'].apply(lambda x: str.split(x, \",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建家庭存活率特征\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "df_data['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "for grp, grp_df in df_data.groupby(['Family_Name', 'Fare']):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "for _, grp_df in df_data.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    df_data.loc[df_data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    df_data.loc[df_data['PassengerId'] == passID, 'Family_Survival'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 1000, 'seed': 2018}\n"
     ]
    }
   ],
   "source": [
    "#回归预测缺失的age\n",
    "def predict_age(x_train, y_train, x_test):\n",
    "    param_grid = {\n",
    "        'learning_rate':[.001, .005, .01, .05, .1],\n",
    "        'max_depth':[2, 4, 6, 8],\n",
    "        'n_estimators':[50, 100, 300, 500, 1000],\n",
    "        'seed':[2018]\n",
    "    }\n",
    "    cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0) \n",
    "    tune_model = model_selection.GridSearchCV(XGBRegressor(nthread=-1), param_grid=param_grid, \n",
    "                                              scoring = 'neg_mean_squared_error', cv = cv_split)\n",
    "    tune_model.fit(x_train, y_train)\n",
    "    print(tune_model.best_params_)\n",
    "    y_test = tune_model.best_estimator_.predict(x_test)\n",
    "\n",
    "    return y_test\n",
    "\n",
    "data_p = df_data.drop(['Cabin', 'Embarked', 'Fare', 'Name', 'PassengerId',\n",
    "                       'Sex', 'Survived', 'Ticket', 'Title', 'Family_Name'], 1)\n",
    "x_train = data_p.loc[~data_p['Age'].isnull(), :].drop('Age', 1)\n",
    "y_train = data_p.loc[~data_p['Age'].isnull(), :]['Age']\n",
    "x_test = data_p.loc[data_p['Age'].isnull(), :].drop('Age', 1)\n",
    "df_data.loc[df_data['Age'].isnull(), 'Age'] = predict_age(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征转换\n",
    "label = LabelEncoder()\n",
    "df_data['Sex_Code'] = label.fit_transform(df_data['Sex'])  # female为0, male为1\n",
    "\n",
    "df_data = pd.concat([df_data, pd.get_dummies(df_data[['Embarked', 'Title', 'Cabin']])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提出特征\n",
    "drop_columns = ['Sex', 'Name', 'Embarked', 'Cabin', 'Ticket', 'Title', 'Family_Name']\n",
    "df_data = df_data.drop(drop_columns, 1)\n",
    "df_data.to_csv(path_data + 'fe_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28.005854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28.005854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>17.898249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch      Fare  \\\n",
       "413         1305       NaN       3  28.005854      0      0    8.0500   \n",
       "414         1306       NaN       1  39.000000      0      0  108.9000   \n",
       "415         1307       NaN       3  38.500000      0      0    7.2500   \n",
       "416         1308       NaN       3  28.005854      0      0    8.0500   \n",
       "417         1309       NaN       3  17.898249      1      1   22.3583   \n",
       "\n",
       "     FamilySize  IsAlone  Family_Survival  ...  Title_Mr  Title_Mrs  \\\n",
       "413           1        1              0.5  ...         1          0   \n",
       "414           1        1              1.0  ...         0          0   \n",
       "415           1        1              0.5  ...         1          0   \n",
       "416           1        1              0.5  ...         1          0   \n",
       "417           3        0              1.0  ...         0          0   \n",
       "\n",
       "     Title_Rare  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_X  \n",
       "413           0        0        0        0        0        0        0        1  \n",
       "414           1        0        0        1        0        0        0        0  \n",
       "415           0        0        0        0        0        0        0        1  \n",
       "416           0        0        0        0        0        0        0        1  \n",
       "417           0        0        0        0        0        0        0        1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集和目标集\n",
    "train = df_data.iloc[:len(df_train),:]\n",
    "test = df_data.iloc[len(df_train):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(columns=['PassengerId','Survived'])\n",
    "train_Y = train['Survived']\n",
    "test_X = test.drop(columns=['PassengerId','Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练XG中\n",
      "Fitting 6 folds for each of 27 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\program files\\python3.6.4\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train score：0.965\n",
      "test score：0.881\n",
      "parameter：{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 400}\n",
      "###########################################\n",
      "训练GBDT中\n",
      "Fitting 6 folds for each of 27 candidates, totalling 162 fits\n",
      "train score：0.984\n",
      "test score：0.874\n",
      "parameter：{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 400}\n",
      "###########################################\n",
      "训练SVC中\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "train score：0.791\n",
      "test score：0.712\n",
      "parameter：{'C': 1}\n",
      "###########################################\n",
      "训练GNB中\n",
      "test score：0.726\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索训练\n",
    "def train_test_model(X_train, y_train, X_test, y_test, model_name, model, param_range):\n",
    "    \n",
    "    print('训练{}中'.format(model_name))   \n",
    "    \n",
    "    clf = GridSearchCV(estimator = model,\n",
    "                       param_grid = param_range,\n",
    "                       cv = 6,\n",
    "                       scoring = 'roc_auc',\n",
    "                       refit = True, verbose = 1, n_jobs = 4)\n",
    "    \n",
    "    clf.fit(X_train, y_train)   \n",
    "    \n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    \n",
    "    print('train score：{:.3f}'.format(train_score))\n",
    "    print('test score：{:.3f}'.format(test_score))\n",
    "    print('parameter：{}'.format(clf.best_params_))\n",
    "    \n",
    "    print('###########################################')\n",
    "    \n",
    "    return clf\n",
    "\n",
    "model_name_param_dict = {\n",
    "                        'XG': (XGBClassifier(),\n",
    "# TODO\n",
    "# 对参数进行调整来得到最优结果                                   \n",
    "                        {'n_estimators':[200,400,800],'max_depth':[5,10,15],'learning_rate':[0.001,0.01,0.1]}),\n",
    "    'GBDT':(GradientBoostingClassifier(),\n",
    "            {'n_estimators':[200,400,800],'max_depth':[5,10,15],'learning_rate':[0.001,0.01,0.1]}),\n",
    "    'SVC':(SVC(),\n",
    "          {'C':[1,0.1,0.01]}),\n",
    "                         }\n",
    "gscv_ls = []\n",
    "for model_name, (model, param_range) in model_name_param_dict.items():\n",
    "    gscv = train_test_model(X_train, y_train, X_test, y_test,model_name, model, param_range)\n",
    "    gscv_ls.append(gscv)\n",
    "print('训练{}中'.format('GNB'))   \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "print('test score：{:.3f}'.format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = gscv_ls[0]\n",
    "#结果保存\n",
    "id=test['PassengerId']\n",
    "id = id.values\n",
    "result=list(zip(id,gscv.predict(test_X)))\n",
    "result=np.array(result)\n",
    "\n",
    "df = pd.DataFrame(result, columns=['PassengerId','Survived'])\n",
    "df['PassengerId'] = df['PassengerId'].astype(np.int32)\n",
    "df['Survived'] = df['Survived'].astype(np.int32)\n",
    "df.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
